---
layout:     post
title:      机器学习
subtitle:   机器学习、核心要素、spark mllib、spark ml、算法、建模
date:       2018-04-05
author:     skylinelin
header-img: img/machine.jpg
catalog: true
tags:
    - 机器学习
    - 核心要素
    - spark mllib
    - spark ml
    - 算法
    - 建模
---

> 什么是机器学习，机器学习的核心要素，机器学习算法以及建模的必要性

## 前提
**在接触机器学习时我们要明白一些概念**

1. 什么是机器学习？machine learning
2. 机器学习的核心要素？
3. spark mllib vs spark ml
4. 机器学习典型四类算法
5. 建模的必要性。

## 什么是机器学习
机器学习可以看做是一门人工智能的科学，该领域的主要研究对象是人工智能。机器学习利用数据或以往的经验，以此优化计算机程序的性能标准。

![jqxx](/resource_img/spark/jqxx.jpg)

 - T:Transformer 转换器
 - E:Estimator 评估器
 - P:Pipeline管道

## 基于大数据的机器学习

 - 传统的机器学习算法，由于技术和单机存储的限制，只能在少量数据上使用，依赖于数据抽样
 - 大数据技术的出现，可以支持在全量数据上进行机器学习
 - 机器学习算法涉及大量迭代计算
 - 基于磁盘的MapReduce不适合进行大量迭代计算
 - 基于内存的Spark比较适合进行大量迭代计算

## Spark 机器学习库MLlib

 - Spark提供了一个基于海量数据的机器学习库，它提供了常用机器学习算法的分布式实现
 - 开发者只需要有Spark基础并且了解机器学习算法的原理，以及方法相关参数的含义，就可以轻松的通过调用相应的API来实现基于海量数据的机器学习过程
 
### MLlib特点

MLlib是Spark的机器学习（Machine Learning）库，旨在简化机器学习的工程实践工作MLlib由一些通用的学习算法和工具组成，包括 **分类、回归、聚类、协同过滤** 等，同时还包括底层的优化原语和高层的流水线（Pipeline）API，具体如下：
 - **算法工具**：常用的学习算法，如分类、回归、聚类和协同过滤
 - **特征化工具**：特征提取、转化和选择工具
 - **流水线**（Pipeline）：用于构建、评估和调整机器学习工作流的工具
 - **持久性**：保存和加载算法、模型和管道
 - **实用工具**：线性代数、统计、数据处理等工具

### MLlib 和 ml

Spark机器学习库从1.2版本以后被分为两个包：
 - **spark.mllib** 包含基于RDD的原始算法API。Spark MLlib历史比较长，在1.0以前的版本即已经包含了，提供的算法实现都是基于原始的RDD
 - **park.ml** 则提供了基于DataFrames高层次的API，可以用来构建机器学习工作流（PipeLine）。ML Pipeline弥补了原始MLlib库的不足，向用户提供了一个基于DataFrame的机器学习工作流式APl套件

### 常见机器学习问题

MLlib目前支持4种常见的机器学习问题：
 - 分类
 - 回归
 - 聚类
 - 协同过滤
 
机器学习问题可大致分为
 - 监督学习
 - 无监督学习
 - 半监督学习
 - 强化学习

![jqxxwt](/resource_img/spark/jqxxwt.jpg)

## 机器学习各组件

### DataFrame
使用Spark SQL中的DataFrame作为数据集，它可以容纳各种数据类型。较之RDD，包含了schema信息，更类似传统数据库中的二维表格。它被ML Pipeline用来存储源数据。例如，DataFrame中的列可以是存储的 **文本** ，特征向量，真实标签和预测的标签等。

### Transformer 转换器
是一种可以将一个DataFrame转换为另一个DataFrame的算法。比如一个模型就是一个Transformer。它可以把一个不包含预测标签的测试数据集DataFrame打上标签，转化成另一个包含预测标签的DataFrame。

技术上，Transformer实现了一个方法transform()，它通过附加一个或多个列将一个DataFrame转换为另一个DataFrame。

### Estimator 评估器
它是学习算法或在训练数据上的训练方法的概念抽象。在Pipeline里通常是被用来操作DataFrame数据并生成一个Transformer。

从技术上讲，Estimator实现了一个方法fit()，它接受一个DataFrame并产生一个转换器。

比如，一个随机森林算法就是一个Estimator，它可以调用fit()，通过训练特征数据而得到一个随机森林模型。

### PipeLine 流水线或者管道
流水线将多个工作流阶段（转换器和估计器）连接在一起，形成机器学习的工作流，并获得结果输出。

## 构建流水线

要构建一个Pipeline流水线，首先需要定义Pipeline中的各个流水线阶段PipelineStage（包括转换器和评估器），比如指标提取和转换模型训练等。有了这些处理特定问题的转换器和评估器，就可以按照具体的处理逻辑有序地组织PipelineStages 并创建一个Pipeline。


```
val pipeline=new Pipeline().setStages(Array(stage1, stage2, stage3,……))
```
流水线的各个阶段按顺序运行，输入的DataFrame在它通过每个阶段时被转换

![jqxxlsx](/resource_img/spark/jqxxlsx.jpg)


> 结尾
