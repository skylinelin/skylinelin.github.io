---
layout:     post
title:      Hadoop-入门基础
subtitle:   Hadoop基础搭建
date:       2017-03-01
author:     skylinelin
header-img: img/Hadoop.png
catalog: true
tags:
    - Hadoop
    - MapReduce
    - Yarn
    - ssh
---

> 介绍Hadoop基本配置，单节点配置以及伪分布式配置，ssh配置

# Hadoop 配置

## Hadoop 目录

目录 | 作用
---|---
bin   | hadoop基本的管理脚本和使用脚本，sbin目录下管理脚本的基本实现。用户可直接通过这个目录来管理和使用Hadoop
etc   | hadoop里面的配置文件
sbin | hadoop里面的管理脚本（例如：HDFS和Yarn里面各种服务的启动脚本和关闭脚本）
share   | hadoop每个模块经过编译之后的jar包
include   | hadoop对外提供的编程库头文件
lib | hadoop对外提供的库文件。这些文件是用来和include里面的编程库头文件相结合来使用的。
libexec   | hadoop各个服务所对应的shell配置文件。这些文件可以用来配置日志输出目录，也可以用来启动参数。

## Hadoop 三大核心，四大模块

#### 三大核心
 - HDFS
 - MapReduce
 - Yarn

#### 四大模块
 - hadoop Common：为其他hadoop模块提供基础设施
 - hadoop DFS：一个高可靠、高吞吐量的分布式文件系统
 - hadoop MapReduce：一个分布式的离线并行计算框架
 - hadoop YARN：新的MapReduce框架，进行任务调度和资源管理

## Hadoop 前置配置

#### 六步配置
配置 | 步骤
---|---
修改 IP 地址 | vi /etc/sysconfig/network-scripts/ifcfg-ens33
修改主机名 | hostname hadoop01(暂时) vi /etc/sysconfig/network(永久)
配置主机名和IP地址映射 | vi /etc/hosts
关闭防火墙 | service iptables stop(暂时)  chkconfig iptables off(永久)
安装 jdk1.8 | 解压或在线安装，然后配置环境变量
配置SSH| 下面又详细步骤

#### SSH 详细配置

SSH 配置 | 步骤
---|---
查看是否安装了SSH | rpm -qa \| grep ssh
查看sshd服务是否启动 | service sshd status
生成密钥 | ssh-keygen -t rsa(三个回车)
将公钥传到另一个节点 | ssh-copy-id hadoop01
测试 | ssh hadoop01

## Hadoop 三种模式

**进行以下的前提是 Hadoop 前置配置完成且未出错**

#### 本地模式

1 进行配置文件 Hadoop-env.sh 的配置  

```
export JAVA_HOME=/usr/local/app/jdk1.8
```

2 执行mapreduce的命令：

```
./bin/hadoop     
jar   
./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar wordcount   
/usr/local/data.txt
```
 
**/usr/local/1**
3  然后会在 **/usr/local** 下生成一个名称为 **1** 的文件，cat 打开进行查看
 
 
---

#### 伪分布式模式

1 安装 Hadoop 并配置环境变量，在 **/etc/profile** 配置上**bin**和**sbin**的环境变量，使得Hadoop命令可以直接使用

2 创建 **/usr/local/app/hadoop_data/dfs** 文件夹，**dfs**文件夹下又**name**和**data**两个文件夹，用来存储**namenode**和**datanode**

3 配置 Hadoop 文件   

 **hadoop-env.sh**  

```
export JAVA_HOME=/usr/local/app/jdk1.8
```

 **core-site.xml**

```
<configuration>
	<property>
	 <name>fs.defaultFS</name>
	 <value>hdfs://localhost:9000</value>
	</property>
</configuration>
```
*注意：可以填写本机IP，如果填写localhost或者主机名，首先要配置IP地址和主机名的映射*  

 **hdfs-site.xml**

```
<configuration>
<!--配置副本数，不得超过主机数-->
	<property>
	    <name>dfs.replication</name>
	    <value>1</value>
	</property>

<!--配置namenode存储路径-->
	<property>
        <name>dfs.name.dir</name>
        <value>/usr/local/app/hadoop_data/dfs/name</value>
    </property>

<!--配置datanode存储路径-->
	<property>
        <name>dfs.data.dir</name>
        <value>/usr/local/app/hadoop_data/dfs/data</value>
    </property>

</configuration>
```


 - mapred-site.xml(目前未配置)
 - yarn-site.xml(目前未配置)

4 以上所有完成后，运行 **Hadoop namenode -format**格式化主节点，这时候 **/usr/local/app/hadoop_data/dfs/name** 下会有 **current** 文件夹和 **in_use.lock** 文件，**current** 文件下有一系列的文件(节点信息、映射文件等)

5 执行 **start-dfs.sh** 命令，然后浏览器输入 [http://192.168.182.12:50070](http://192.168.182.12:50070) 就可以看到Hadoop监控界面
 
 
---

## Hadoop 常用端口


端口 | 作用
---|---
**9000** | **namenode 常用端口，给机子**
**8020** | **namenode 的RPC调用端口 (接收Client连接的RPC端口，用于获取文件系统的metadata信息)**
**50070** | **namenode http HDFS查看端口 web**
50470 | https 查看 HDFS 端口
**50090** | **sencondaryNamenode**
**8088** | **ResourceManager YARN集群端口**
**8089** | **Web Application Proxy web代理**
10020 | JobHistory(host)
**19888** | **JobHistory(web)**
8030-8033 | resourcemanage 组件

*注意：以上加粗端口必须记忆*

> 结尾





