---
layout:     post
title:      Hive
subtitle:   Hive系统架构、Hive介绍、Hive执行流程
date:       2017-04-05
author:     skylinelin
header-img: img/post-bg-map.jpg
catalog: true
tags:
    - Hive
    - RDBMS
    - Hive特点
    - 执行流程
---

> 重点Hive系统架构图，掌握Hive执行流程

## 什么是Hive

1、Hive 由 Facebook 实现并开源

2、是基于 Hadoop 的一个数据仓库工具

3、可以将结构化的数据映射为一张数据库表

4、并提供 HQL(Hive SQL)查询功能

5、底层数据是存储在 HDFS 上

6、Hive的本质是将 SQL 语句转换为 MapReduce 任务运行

7、使不熟悉 MapReduce 的用户很方便地利用 HQL 处理和计算 HDFS 上的结构化的数据，适用于离线的批量数据计算。

**Hive 依赖于 HDFS 存储数据，Hive 将 HQL 转换成 MapReduce 执行，所以说 Hive 是基于 Hadoop 的一个数据仓库工具，实质就是一款基于 HDFS 的 MapReduce 计算框架，对存储在 HDFS 中的数据进行分析和管理。**

![hiveyx](/resource_img/hiveyx.jpg)

## 为什么使用 Hive

直接使用 MapReduce 所面临的问题：

 - 人员学习成本太高
 - 项目周期要求太短
 - MapReduce实现复杂查询逻辑开发难度太大

为什么要使用 Hive：

 - **更友好的接口**：操作接口采用类 SQL 的语法，提供快速开发的能力
 - **更低的学习成本**：避免了写 MapReduce，减少开发人员的学习成本
 - **更好的扩展性**：可自由扩展集群规模而无需重启服务，还支持用户自定义函数

## Hive 特点

**优点：**

1. **可扩展性,横向扩展**：Hive 可以自由的扩展集群的规模，一般情况下不需要重启服务 横向扩展：通过分担压力的方式扩展集群的规模 纵向扩展：一台服务器cpu i7-6700k 4核心8线程，8核心16线程，内存64G => 128G
2. **延展性**：Hive 支持自定义函数，用户可以根据自己的需求来实现自己的函数
3. **良好的容错性**：可以保障即使有节点出现问题，SQL 语句仍可完成执行

**缺点：**

1. **Hive 不支持记录级别的增删改操作**：但是用户可以通过查询生成新表或者将查询结 果导入到文件中（当前选择的 hive-2.3.2 的版本支持记录级别的插入操作）
2. **Hive 的查询延时很严重**：因为 MapReduce Job 的启动过程消耗很长时间，所以不能 用在交互查询系统中。
3. **Hive 不支持事务**：（因为不没有增删改，所以主要用来做 OLAP（联机分析处理），而 不是 OLTP（联机事务处理），这就是数据处理的两大级别）。

## Hive 和 RDBMS 的对比


对比项 | Hive | RDBMS
---|--- |---
查询语言 | HQL | SQL
**数据存储**  | HDFS | Raw Device or local FS
**执行器** | MapReduce | Executor
数据插入 | 支持批量导入、单条插入 | 支持单条或者批量导入
**数据操作** | 覆盖追加 | 行级更新删除
**处理数据规模** | 大 | 小
执行延迟 | 高 | 低
分区 | 支持 | 支持
索引 | 0.8版本以后加入简单的索引 |支持复杂的索引
扩展性 | 高（好） | 有限（差）
数据加载模式 | 读时模式（快） | 写时模式（慢）
**应用场景** | 海量数据查询 | 实时查询



## Hive架构

![hivejg](/resource_img/hivejg.png)


*通过上图可知，Hive的架构由四部分组成*

### 1、用户接口: shell/CLI, jdbc/odbc, webui Command Line Interface

 - **CLI**：Shell 终端命令行（Command Line Interface），采用交互形式使用 Hive 命令行与 Hive 进行交互，最常用（学习，调试，生产）
 - **JDBC/ODBC**：是 Hive 的基于 JDBC 操作提供的客户端，用户（开发员，运维人员）通过 这连接至 Hive server 服务
  - **Web UI**：通过浏览器访问 Hive

### 2、跨语言服务 ： thrift server 提供了一种能力，让用户可以使用多种不同的语言来操纵hive

Thrift 是 Facebook 开发的一个软件框架，可以用来进行可扩展且跨语言的服务的开发， Hive 集成了该服务，能让不同的编程语言调用 Hive 的接口。

### 3、底层的Driver： 驱动器Driver，编译器Compiler，优化器Optimizer，执行器Executor

Driver 组件完成 HQL 查询语句从词法分析，语法分析，编译，优化，以及生成逻辑执行 计划的生成。生成的逻辑执行计划存储在 HDFS 中，并随后由 MapReduce 调用执行

Hive 的核心是驱动引擎， 驱动引擎由四部分组成：

1. **解释器**：解释器的作用是将 HiveSQL 语句转换为抽象语法树（AST）
2. **编译器**：编译器是将语法树编译为逻辑执行计划
3. **优化器**：优化器是对逻辑执行计划进行优化
4. **执行器**：执行器是调用底层的运行框架执行逻辑执行计划

### 4、元数据存储系统 ： RDBMS MySQL

元数据，通俗的讲，就是存储在 Hive 中的数据的描述信息。

Hive 中的元数据通常包括：表的名字，表的列和分区及其属性，表的属性（内部表和 外部表），表的数据所在目录

Metastore 默认存在自带的 Derby 数据库中。缺点就是不适合多用户操作，并且数据存 储目录不固定。数据库跟着 Hive 走，极度不方便管理

解决方案：通常存我们自己创建的 MySQL 库（本地 或 远程）

Hive 和 MySQL 之间通过 MetaStore 服务交互

## 执行流程

HiveQL 通过命令行或者客户端提交，经过 Compiler 编译器，运用 MetaStore 中的元数 据进行类型检测和语法分析，生成一个逻辑方案(Logical Plan)，然后通过的优化处理，产生 一个 MapReduce 任务。

> 结尾
